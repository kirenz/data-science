[["index.html", "Data Science Basics Welcome License Acknowledements", " Data Science Basics Jan Kirenz 2021-01-07 Welcome How can we effectively and efficiently teach data science to students with little to no background in computing and statistical thinking? How can we equip them with the skills and tools for reasoning with various types of data and leave them wanting to learn more? This introductory data science course is our (working) answer to this question. The source code for everything you see here can be found on GitHub. The core content of the course focuses on data acquisition and wrangling, exploratory data analysis, data visualization, inference, modelling, and effective communication of results. Time permitting, the course also introduces additional concepts and tools like interactive visualization and reporting, text analysis, and Bayesian inference. A heavy emphasis is placed on a consistent syntax (with tools from the tidyverse), reproducibility (with R Markdown), and version control and collaboration (with Git and GitHub). In addition, out-of-class learning is supplemented with interactive tutorials. The goal of the course is to bring students from zero to being able to work in a team on a fully reproducible data science project analysing a dataset of their choice and answering questions they care about. Data Science in a Box contains the materials required to teach (or learn from) the course described above, all of which are freely-available and open-source. They include course materials such as slide decks, homework assignments, guided labs, sample exams, a final project assignment, as well as materials for instructors such as pedagogical tips, information on computing infrastructure, technology stack, and course logistics. Majority of the materials linked live in the GitHub repo serving this website. You can access the repo here. Please note that Data Science in a Box uses a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms. License This online work is licensed under a Creative Commons Attribution-ShareAlike 4.0 Internationale. Visit here for more information about the license. Acknowledements Huge thanks to the #rstats education community who have made numerous suggestions for this resource, to Lee Suddaby and Zeno Kujawa for converting the homework assignments to learnr tutorials, and to Müge Çetinkaya for the hex logo! This website is built with bookdown, the lovely icons by icons8, and none of this would be possible without the tidyverse. "],["overview.html", "Chapter 1 Overview 1.1 Who is this course for? 1.2 Where does this course fit in a curriculum? 1.3 What is in the box? 1.4 Why R? 1.5 Why not language X? 1.6 Why RStudio? 1.7 Learn more", " Chapter 1 Overview Hello! And welcome! There is a little bit of something for everyone (who wants to teach/learn) data science in this box. If you are an educator we recommend consuming the content in the order presented here: first familiarize yourself with the design principles, course syllabus, and the tech stack, then browse the course content, and then review the details of the computing infrastructure and pedagogy of the course. If you are a learner, you might consider jumping straight into the course content. 1.1 Who is this course for? There are two answers to this question, depending on whether you are a learner or educator. (And really, aren’t we all both?) Learner persona If you are a learner who is interested in making sense of (sometimes messy) data and who has little to no background in data science, statistics, or programming, or has been using R for a while but wants to modernize their skills, the materials in this course are for you! The content is definitely newcomer friendly, however you should be willing to ask questions and dive into the documentation of the packages we introduce. Note that course prerequisites are not listed, and this is not an oversight. The course is designed to be accessible to new learners at the undergraduate level and above, though adventurous learners at the high school level might also enjoy these materials. Educator persona If you are an educator who is / will be teaching data science at the introductory level and who has been teaching with R for a while but wants to update bits of or completely overhaul their teaching materials, or is new to teaching (with) R but otherwise comfortable with the basics of the language the course materials provided here are for you. The course is designed to be taught at the introductory undergraduate level and above, however it is possible to re-purpose much of this content at the high school level as well. Note that a specific discipline is not mentioned, and this is not an oversight. Many disciplines are offering their version of introductory data science nowadays, and we think more the merrier! The course draws on data sets primarily from the social sciences and humanities, and a few from natural sciences. 1.2 Where does this course fit in a curriculum? This course can serve as a first course in an undergraduate data science or statistics curriculum. It can also serve as an introductory course in a graduate program, and depending on the background of the students, earlier topics can be covered more quickly to make room for more content at the end of the course. 1.3 What is in the box? Student facing materials: slides: 30 slide decks, each to be covered roughly in a 75 minute class session application exercises: 10 application exercises assignments: 8 homework assignments labs: 12 guided hands on exercises for students requiring minimal introduction from the instructor exams: 2 sample take-home exams and keys project: Final project assignment tutorials: 8 interactive learnr tutorials Educator facing materials: Computing infrastructure: RStudio: Choosing between RStudio Cloud, RStudio Server Pro, or local RStudio IDE and how to structure your course using each option Git/GitHub: How to use Git and GitHub as the learning management system for your course as well as a collaborative platform for your students and how to use GitHub Classroom and ghclass for setting up your course Creating learnr modules Using blogdown to create your course website Pedagogical tips 1.4 Why R? Unlike most other software designed specifically for teaching statistics, R is free and open source, powerful, flexible, and relevant beyond the introductory statistics classroom. Arguments against using and teaching R at especially the introductory statistics level generally cluster around the following two points: teaching programming in addition to statistical concepts is challenging and the command line is more intimidating to beginners than the graphical user interface (GUI) most point-and-click type software offer. One solution for these concerns is to avoid hands-on data analysis completely. If we do not ask our students to start with raw data and instead always provide them with small, tidy rectangles of data then there is never really a need for statistical software beyond spreadsheet or graphing calculator. This is not what we want in a modern statistics course and is a disservice to students. Another solution is to use traditional point-and-click software for data analysis. The typical argument is that the GUI is easier for students to learn and so they can spend more time on statistical concepts. However, this ignores the fact that these software tools also have nontrivial learning curves. In fact, teaching specific data analysis tasks using such software often requires lengthy step-by-step instructions, with annotated screenshots, for navigating menus and other interface elements. Also, it is not uncommon that instructions for one task do not easily extend to another. Replacing such instructions with just a few lines of R code actually makes the instructional materials more concise and less intimidating. Many in the statistics education community are in favor of teaching R (or some other programming language, like Python) in upper level statistics courses, however the value of using R in introductory statistics courses is not as widely accepted. We acknowledge that this addition can be burdensome, however we would argue that learning a tool that is applicable beyond the introductory statistics course and that enhances students’ problem solving skills is a burden worth bearing. 1.5 Why not language X? There are a number of other great programming tools out there that can also be used for introducing students to data science, e.g. Python. These materials are designed for teaching data science with R. A great example of a similar curriculum using Python is Data 8 designed at University of California, Berkeley. 1.6 Why RStudio? The RStudio IDE includes a viewable environment, a file browser, data viewer, and a plotting pane, which makes it less intimidating than the bare R shell. Additionally, since it is a full fledged IDE, it also features integrated help, syntax highlighting, and context-aware tab completion, which are all powerful tools that help flatten the learning curve. RStudio also has direct integration with other critically important tools for teaching computing best practices and reproducible research. Our recommendation is that students access the RStudio IDE through a centralized RStudio server instance or using RStudio Cloud. We describe this in further detail in the Infrastructure section. It should be noted that we do not want to completely dissuade students from downloading and installing R and RStudio locally, we just do not want it to be a prerequisite for getting started. We have found that teaching personal setup is best done progressively throughout a semester, usually via one-on-one interactions during office hours or after class. Our goal is that all students will be able to continue using R in any setting. 1.7 Learn more If you would like to learn more about the design philosophy behind the course as well as implementation details, we recommend the following paper that is freely available online. Mine Çetinkaya-Rundel &amp; Victoria Ellison (In press), A fresh look at introductory data science, Journal of Statistics Education. doi.org/10.1080/10691898.2020.1804497. "],["design-principles.html", "Chapter 2 Design principles 2.1 Start with cake 2.2 Cherish day one 2.3 Skip baby steps 2.4 Hide the veggies 2.5 Leverage the ecosystem 2.6 Learn more", " Chapter 2 Design principles This course is designed with five principles in mind: Start with cake Cherish day one Skip baby steps Hide the veggies Leverage the ecosystem 2.1 Start with cake Assuming you like chocolate and strawberries, which of the following images is more likely to make you want to learn to bake a cake? I’m guessing the answer is the image on the left: the cake. The teaching philosophy of this course builds on this same idea. We first show the students the end result, and then step back and teach the necessary components. Specifically, instead of starting with data structures and functions, we start data visualization. And not just a toy example, but a complex, multivariate data visualization. Of course, we don’t want students feeling like… The course goes starts out slow and emphasizes iteration. Students are initially provided with lots of scaffolding, and then slowly we take away the scaffolding until they are starting with a blank slate for their final projects. 2.2 Cherish day one Don’t spend the first day going through the syllabus in detail, aim to get students to make their first meaningful data visualization in 10 minutes! This might sound impossible, and it probably is, if you start by installing R, and then RStudio, and then a bunch of packages, and making sure students have Git working on their computer. You could spend a whole class (or more) on this and not get to a point where every student has their local setup working in an ideal fashion. Instead, use cloud-based access to RStudio. This could be via RStudio Cloud or an RStudio Server you set up locally at your institution. Find out more about how you can set up your computing infrastructure for friction-less onboarding here. 2.3 Skip baby steps It’s tempting to start teaching with the simplest examples, e.g. starting data visualization with a bar graph of a single categorical variable instead of a multivariate faceted visualization, especially when teaching programming to build these visualizations since with complex examples comes an extensive amount of code. Unfortunately very basic data visualizations are rarely as motivating as those telling the story of the relationship between a number of variables at once. With the right choice of language and syntax, one can achieve the goal of starting with motivating and complex examples, and building up to such examples along the way. The ggplot2 package, a system for declaratively creating graphics, based on The Grammar of Graphics allows for just this in the context of data visualization. Similarly, the data wrangling packages dplyr and tidyr work really well with the pipe (%&gt;%) operator in R, which allows for building up your data manipulation and analysis in a step-wise fashion, similar in spirit to ggplot2’s layers. 2.4 Hide the veggies This is somewhat tongue-in-cheek. Veggies are absolutely good for you, and it is important that you learn to enjoy them. However many people wouldn’t list raw broccoli as their favourite food, however good it might be for them. Similarly there are many aspects of data science and programming that students must absolutely learn and understand the importance of, even if they are not the most exciting part of their data science journey. For example, one cannot do justice to working with text data without discussing regular expressions. However regular expressions are likely going to be a pain point in the learning journey of newcomers with little to no prior programming experience. So, in this course, instead of teaching students the basics of regular expressions as a unit, we hide this topic within the context of web scraping and manipulating text fields into multiple columns to get what we want out of them. 2.5 Leverage the ecosystem The course materials make heavy use of the tidyverse for data visualization and data wrangling. However, until recently, there was a gap in the R ecosystem for doing basic statistical inference using a syntax that follows tidyverse design principles. This prompted the developments of infer, a package for performing statistical inference using an expressive statistical grammar that coheres with the tidyverse design framework. Using infer to introduce statistical inference makes the transition from the first to the second unit of the course much smoother, and the development of the package as a collaboration between like-minded educators is a great example of leveraging an existing ecosystem to provide a smoother learning experience for students. Similarly, on the instructor facing side, course organization on GitHub is managed by the ghclass package. And the course slides are built with xaringan, and course website is built with blogdown. Leveraging all of these packages allows the instructor to live and breathe in R for all aspects of running their course. 2.6 Learn more The following talk titled “Let them eat cake (first)!” describes in further detail and with examples from the course materials each of the design principles outlined above. "],["topics.html", "Chapter 3 Topics", " Chapter 3 Topics The course content is organized in three units: Unit 1 - Hello world: This unit is an introduction to the content, pedagogy, and toolkit of the course. Unit 2 - Exploring data: This unit focuses on data visualization and data wrangling. Specifically we cover fundamentals of data and data visualization, confounding variables, and Simpson’s paradox as well as the concept of tidy data, data import, data cleaning, and data curation. We end the unit with web scraping and introduce the idea of iteration in preparation for the next unit. Also in this unit students are introduced to the toolkit: R, RStudio, R Markdown, Git, and GitHub. Unit 3 - Data science ethics: In this unit we discuss misrepresentation of findings, particularly in data visualisations, breaches of data privacy, and algorithmic bias. Unit 4 - Making rigorous conclusions: In this unit we introduce modelling and statistical inference for making data-based conclusions. We discuss building, interpreting, and selecting models, visualizing interaction effects, and prediction and model validation. Statistical inference is introduced from a simulation based perspective, and the Central Limit Theorem is discussed very briefly to lay the foundation for future coursework in statistics. Unit 5 - Looking forward: In the last unit we present a series of modules such as interactive reporting and visualization with Shiny, text analysis, and Bayesian inference. These are independent modules that educators can choose to include in their introductory data science curriculum depending on how much time they have left in the semester. "],["tech-stack.html", "Chapter 4 Tech stack", " Chapter 4 Tech stack This course teaches computing and statistics to undergraduates with no background in either. Managing such a course with students from varied backgrounds doing non-trivial computational work is a big technical challenge. This page briefly describes the toolkit choices, and the Infrastructure part provides a path forward for educators who are considering using these tools for their own teaching purposes. While the recommended tech stack for the entirety of course development is tall, only a few of the technologies are student facing: RStudio Cloud: RStudio Cloud is a managed cloud instance of the RStudio IDE. We recommend having students access RStudio via RStudio Cloud as opposed to using a local installation. See Section 14 for more on this. GitHub: The use of GitHub also goes a long way to help students visualize and understand the git process which also aids in student buy-in. The web interface allows students to easily view diffs (file changes over time) in files they are collaborating on, keep track of commit histories, and search both the current state as well as the entire history of the code base. Within the classroom GitHub can be thought of as an advanced and flexible learning management system (compared to traditional tools like Blackboard or Sakai). See Section 15 for more on this. Piazza: Piazza is an easy to use and free Q&amp;A platform that your students might very well be already familiar with from other classes. It is also possible that it’s already integrated into your learning management system if you’re teaching in a university setting. Students are discouraged from using email for questions and discussions related to content of the course, only emails about personal matters are allowed. Hence most course communication happens on Piazza. Both public (for announcements and general questions) and private (for team communication) channels are used. Note that Piazza is not everyone’s first choice, a few options for alternatives used in statistics and data science courses can be found on this Twitter thread. "],["community.html", "Chapter 5 Community", " Chapter 5 Community Do you like what’s in the box? Do you have questions? Is something you need missing? Want to exchange ideas with others teaching similar courses? We now have a dsbox Slack channel, you can join here.1 The Slack channel is a place for discussion on using these or similar materials in data science courses. Please make sure to review the Code of Conduct before joining. Other great venues for questions are the RStudio Community under Teaching or #rstats Twitter. Additionally, we would love to hear from you if you are using these resources. Please take just a few minutes to fill out this Google form. All fields are optional, but the more information you provide, the more data we will have to assess the reach and impact of this project. If the link has expired, please email me at cetinkaya.mine@gmail.com to request a new one.↩︎ "],["hello-world.html", "Chapter 6 Hello world 6.1 Slides, videos, and application exercises", " Chapter 6 Hello world I recommend starting the class off right, devoting more of the class time to introducing the course content instead of the course policies. And get students doing something with data as quickly as possible! A personal goal of mine is to get students to produce their first data visualization within the first 10 minutes of class. The application exercise in this lecture is one way of achieving this goal. Slides for Day One of class are provided below. Note that getting students computing on Day One in class requires that they come to class equipped with a laptop or that you’re holding your course online or in a computer lab. If teaching online, this is resolved automatically, of course. They do not need to do any preparation ahead of time, just need internet access. As outlined in the slides, give them a link to your RStudio Cloud workspace and get them started working on the application exercise you put together for them. There are two options for a day one application exercise. Note that one of them uses COVID-19 data and depending on where, when, and to whom you’re teaching, working with these data might not be the most pleasant experience for all students. Please make sure to consider this before using this activity. The RStudio Cloud workspace for Data Science Course in a Box project is here. You can join the workspace and play around with the sample application exercises. 6.1 Slides, videos, and application exercises Unit 1 - Deck 1: Welcome Slides Source Video First dataviz Option 1 - UN Votes Source Video Option 2 - COVID-19 Source Unit 1 - Deck 2: Meet the toolkit - Programming Slides Source Video R4DS :: Chp 2 - Introduction IMS :: Sec 1.1 &amp; 1.2 - Case study &amp; Data basics Bechdel + R Markdown Source Unit 1 - Deck 3: Meet the toolkit - Version control and collaboration Slides Source Video "],["exploring-data.html", "Chapter 7 Exploring data 7.1 Slides, videos, and application exercises 7.2 Labs 7.3 Homework assignments", " Chapter 7 Exploring data This unit focuses on data visualization and data wrangling. Specifically we cover fundamentals of data and data visualization, confounding variables, and Simpson’s paradox as well as the concept of tidy data, data import, data cleaning, and data curation. We end the unit with web scraping and introduce the idea of iteration in preparation for the next unit. Also in this unit students are introduced to the toolkit: R, RStudio, R Markdown, Git, and GitHub. The RStudio Cloud workspace for Data Science Course in a Box project is here. You can join the workspace and play around with the application exercises. 7.1 Slides, videos, and application exercises 7.1.1 Visualising data Unit 2 - Deck 1: Data and visualisation Slides Source Video Unit 2 - Deck 2: Visualising data with ggplot2 Slides Source Video R4DS :: Chp 3 - Data visualization Unit 2 - Deck 3: Visualising numerical data Slides Source Video IMS :: Sec 2.1 - Exploring numerical data Unit 2 - Deck 4: Visualising categorical data Slides Source Video IMS :: Sec 2.2 - Exploring categorical data StarWars + Dataviz Source Video 7.1.2 Wrangling and tidying data Unit 2 - Deck 5: Tidy data Slides Source Video JSS :: Tidy data Unit 2 - Deck 6: Grammar of data wrangling Slides Source Video Unit 2 - Deck 7: Working with a single data frame Slides Source Video R4DS :: Chp 5 - Data transformation Unit 2 - Deck 8: Working with multiple data frames Slides Source Video R4DS :: Chp 13 - Relational data Unit 2 - Deck 9: Tidying data Slides Source Video R4DS :: Chp 12 - Tidy data Hotels + Data wrangling Source Video 7.1.3 Importing and recoding data Unit 2 - Deck 10: Data types Slides Source Video Unit 2 - Deck 11: Data classes Slides Source Video R4DS :: Chp 15 - Factors Unit 2 - Deck 12: Importing data Slides Source Video R4DS :: Chp 11 - Data import Unit 2 - Deck 13: Recoding data Slides Source Video R4DS :: Sec 16.1 - 16.3 - Dates and times Hotels + Data types Source Source Video Nobels + Sales + Data import Source Source Video 7.1.4 Communicating data science results effectively Unit 2 - Deck 14: Tips for effective data visualization Slides Source Video IMS :: Sec 2.3 - Effective data visualisation Brexit + Telling stories with dataviz Source Video Unit 2 - Deck 15: Scientific studies and confounding Slides Source Video IMS :: Sec 1.3 - Sampling principles and strategies IMS :: Sec 1.4 - Experiments Unit 2 - Deck 16: Simpson’s paradox Slides Source Video Unit 2 - Deck 17: Doing data science Slides Source Video R4DS :: Chp 7 - Exploratory data analysis 7.1.5 Web scraping and programming Unit 2 - Deck 18: Web scraping Slides Source Video Unit 2 - Deck 19: Scraping top 250 movies on IMDB Slides Source Video Unit 2 - Deck 20: Web scraping considerations Slides Source Video IMDB + Web scraping Source Video Unit 2 - Deck 21: Functions Slides Source Video R4DS :: Chp 19 - Functions Unit 2 - Deck 22: Iteration Slides Source Video R4DS :: Chp 20 - Iteration 7.2 Labs Lab 1: Hello R Introduction to R, R Markdown, Git, and GitHub Instructions Source Starter Lab 2: Plastic waste Introduction to working with data in R with the tidyverse Instructions Source Starter Lab 3: Nobel laureates Data wrangling and tidying Instructions Source Starter Lab 4: La Quinta is Spanish for ‘next to Denny’s’, Pt. 1 Visualizing spatial data Instructions Source Starter Lab 5: La Quinta is Spanish for ‘next to Denny’s’, Pt. 2 Wrangling spatial data Instructions Source Starter Lab 6: Sad plots Critiquing and improving data visualisations Instructions Source Starter Lab 7: Simpson’s paradox Data visualisation, confounding, multivariable relationships Instructions Source Starter Lab 8: University of Edinburgh Art Collection Web scraping, function, iteration Instructions Source Starter 7.3 Homework assignments HW 1: Pet names Introduction to working with data in R with the tidyverse Instructions Source Starter HW 2: Edinburgh Airbnb rentals Data visualisation with the tidyverse Instructions Source Starter HW 3: Road traffic accidents Data wrangling, tidying, and visualization Instructions Source Starter HW 4: What should I major in? More data wrangling, summarizing, and visualization Instructions Source Starter HW 5: Legos More data wrangling, summarizing, and visualization Instructions Source Starter HW 6: Money in politics Web scraping, functions, and iteration Instructions Source Starter "],["ethics.html", "Chapter 8 Data science ethics 8.1 Slides, videos, and application exercises 8.2 Labs", " Chapter 8 Data science ethics This unit touches on data science ethics, specifically on issues of misrepresentation of data and results, data privacy, and algorithmic bias. Course lectures are supplemented with “guest lectures” from domain experts. 8.1 Slides, videos, and application exercises Unit 3 - Deck 1: Misrepresentation Slides Source Video Alberto Cairo - How charts lie Video Unit 3 - Deck 2: Data privacy Slides Source Video The Guardian - Cambridge Analytica whistleblower Video Unit 3 - Deck 3: Algorithmic bias Slides Source Video Joy Buolamwini - How I’m fighting bias in algorithms Video Cathy O’Neil - Weapons of Math Destruction Video Safiya Umoja Noble - Imagining a Future Free from the Algorithms of Oppression Video Kristian Lum - What’s An Algorithm Got To Do With It Video 8.2 Labs Lab 9: Conveying the right message through visualisation Improving data visualisations to better convey the right message Instructions Source Starter "],["making-rigorous-conclusions.html", "Chapter 9 Making rigorous conclusions 9.1 Slides, videos, and application exercises 9.2 Labs 9.3 Homework assignments", " Chapter 9 Making rigorous conclusions In this part we introduce modelling and statistical inference for making data-based conclusions. We discuss building, interpreting, and selecting models, visualizing interaction effects, and prediction and model validation. Statistical inference is introduced from a simulation based perspective, and the Central Limit Theorem is discussed very briefly to lay the foundation for future coursework in statistics. The RStudio Cloud workspace for Data Science Course in a Box project is here. You can join the workspace and play around with the sample application exercises. 9.1 Slides, videos, and application exercises 9.1.1 Modelling data Unit 4 - Deck 1: The language of models Slides Source Video Unit 4 - Deck 2: Fitting and interpreting models Slides Source Video IMS :: Chp 3 - Introduction to linear models Unit 4 - Deck 3: Modelling nonlinear relationships Slides Source Video Unit 4 - Deck 4: Models with multiple predictors Slides Source Video IMS :: Sec 4.1 - Regression with multiple predictors Unit 4 - Deck 5: More models with multiple predictors Slides Source Video 9.1.2 Classification and model building Unit 4 - Deck 6: Logistic regression Slides Source Video IMS :: Sec 4.5 - Logistic regression Unit 4 - Deck 7: Prediction and overfitting Slides Source Video tidymodels :: Build a model Unit 4 - Deck 8: Feature engineering Slides Source Video tidymodels :: Preprocess your data with recipes 9.1.3 Model validation Unit 4 - Deck 9: Cross validation Slides Source Video tidymodels :: Evaluate your model with resampling The Office + Feature engineering, Pt. 1 Source Video The Office + Cross validation, Pt. 2 Source Video 9.1.4 Uncertainty quantification Unit 4 - Deck 10: Quantifying uncertainty Slides Source Video Unit 4 - Deck 11: Bootstrapping Slides Source Video IMS :: Sec 5.2 - Bootstrap confidence intervals Unit 4 - Deck 12: Hypothesis testing Slides Source IMS :: Sec 5.1 - Randomization tests Unit 4 - Deck 13: Inference overview Slides Source 9.2 Labs Lab 10: Grading the professor, Pt. 1 Fitting and interpreting simple linear regression models Instructions Source Starter Lab 11: Grading the professor, Pt. 2 Fitting and interpreting multiple linear regression models Instructions Source Starter Lab 12: Smoking while pregnant Constructing confidence intervals, conducting hypothesis tests, and interpreting results in context of the data Instructions Source Starter 9.3 Homework assignments HW 7: Bike rentals in DC Exploratory data analysis and fitting and interpreting models Instructions Source Starter HW 8: Exploring the GSS Fitting and interpreting models Instructions Source Starter HW 9: Modelling the GSS Model validation and inference Instructions Source Starter "],["looking-forward.html", "Chapter 10 Looking further 10.1 Slides, videos, and application exercises 10.2 Labs 10.3 Homework assignments", " Chapter 10 Looking further In the last unit we present a series of modules such as interactive reporting and visualization with Shiny, text analysis, machine learning, and Bayesian inference. These are independent modules that educators can choose to include in their introductory data science curriculum depending on how much time they have left in the semester. Note that the slides in this unit are a bit more sparse than the others, and much of the content is delivered as live coding sessions. 10.1 Slides, videos, and application exercises Unit 5 - Deck 1: Text analysis Slides Source Video Unit 5 - Deck 2: Comparing texts Slides Source Video Unit 5 - Deck 3: Interactive web apps Slides Source Video Unit 5 - Deck 4: Machine learning Slides Source Video Unit 5 - Deck 5: Interactive data visualisation Slides Unit 5 - Deck 6: Interactive data visualisation and reporting Slides Unit 5 - Deck 7: Bayesian inference Slides Source 10.2 Labs Lab 13: Working on projects Fitting and interpreting simple linear regression models Instructions Source Lab 14: Collaboration on GitHub Fitting and interpreting simple linear regression models Instructions Source 10.3 Homework assignments HW 10: Wrapping up Model validation and inference Instructions Source Starter "],["interactive-tutorials.html", "Chapter 11 Interactive tutorials", " Chapter 11 Interactive tutorials The following interactive tutorials have been built with learnr and gradethis. They’re available on shinyapps.io (linked) as well as distributed with the dsbox package.2 With the dsbox package installed, you can also run these tutorials in the Tutorials pane of your RStudio window. This might be preferable for courses with high enrollment where students need to access the tutorials at the same time. Note that many of these include examples and questions from the homework assignments listed earlier. You can think of these as interactive, auto-feedback versions of the simpler questions in the homework assignments. If using both the tutorials and the homework assignments in your teaching, I recommend modifying the homework assignments to remove the redundant questions (they will usually be the earlier, shorter, simpler questions) and making the homework assignment shorter. Students will ultimately get exposed to the same material, but get auto-feedback in the tutorials and human feedback on the homework assignments. If you would like to learn about making your own tutorials with learnr, I strongly recommend reviewing the video and materials from the following 1.5 hour workshop: Building interactive tutorials in R. Tutorial 1: Airbnb listings in Edinburgh The goal of this tutorial is not to conduct a thorough analysis of Airbnb listings in Edinburgh, but instead to give you a chance to practice your data visualisation and interpretation skills. [Tutorial] [Source] Tutorial 2: Road Traffic Accidents Continue practising data visualization skills with ggplot2. Filter data for certain attributes with filter(). Create new variables based on existing variables in the data with mutate(). [Tutorial] [Source] Tutorial 3: What should I major in? Continue practising data tidying and visualisation. Calculate summary statistics with summarise(). Arrange output of dplyr chains with arrange(). [Tutorial] [Source] Tutorial 4: Lego sales Practice the analysis skills you have learned so far. Develop a question you can answer with the data. Deepen your understanding of building and interpreting visualisations. [Tutorial] [Source] Tutorial 5: Money in US politics Get started with scraping data from the web. Continue to build on your data cleaning and visualisation skills. [Tutorial] [Source] Tutorial 6: Bike Rentals in D.C. Continue to hone your data wrangling skills. Practice modelling and interpreting model results and performance. Conduct backwards selection for finding the “best” model. [Tutorial] [Source] Tutorial 7: Exploring the General Social Survey Work on your data manipulation skills. Fit linear models with multiple predictors. Interpret regression output. [Tutorial] [Source] Tutorial 8: Bootstrapping the General Social Survey Continue to hone your data wrangling skills. Use bootstrapping to construct confidence intervals. Interpret of confidence intervals in context of the data. [Tutorial] [Source] The dsbox package is not yet on CRAN, until then you will need to install from GitHub with devtools::install_github(\"rstudio-education/dsbox\").↩︎ "],["project.html", "Chapter 12 Project 12.1 TL;DR 12.2 May be too long, but please do read 12.3 Data", " Chapter 12 Project The following is a sample project assignment for this curriculum. You can find the source code for this assignment write up here. I’ve also provided sample evaluation forms to be used by the teaching team and students as well as a sample repo structure for the project. 12.1 TL;DR Pick a dataset, any dataset… …and do something with it. That is your final project in a nutshell. More details below. 12.2 May be too long, but please do read The final project for this class will consist of analysis on a dataset of your own choosing. The dataset may already exist, or you may collect your own data using a survey or by conducting an experiment. You can choose the data based on your interests or based on work in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like) and apply them to a novel dataset in a meaningful way. The goal is not to do an exhaustive data analysis i.e., do not calculate every statistic and procedure you have learned for every variable, but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using R, and that you are proficient at interpreting and presenting the results. Focus on methods that help you begin to answer your research questions. You do not have to apply every statistical procedure we learned (and you can use techniques we haven’t officially covered in class, if you’re feeling adventurous). Also, critique your own methods and provide suggestions for improving your analysis. Issues pertaining to the reliability and validity of your data, and appropriateness of the statistical analysis should be discussed here. The project is very open ended. You should create some kind of compelling visualization(s) of this data in R. There is no limit on what tools or packages you may use, but sticking to packages we learned in class (tidyverse) is required. You do not need to visualize all of the data at once. A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations. Also pay attention to your presentation. Neatness, coherency, and clarity will count. All analyses must be done in RStudio, using R. 12.3 Data In order for you to have the greatest chance of success with this project it is important that you choose a manageable dataset. This means that the data should be readily accessible and large enough that multiple relationships can be explored. As such, your dataset must have at least 50 observations and between 10 to 20 variables (exceptions can be made but you must speak with me first). The dataset’s variables should include categorical variables, discrete numerical variables, and continuous numerical variables. If you are using a dataset that comes in a format that we haven’t encountered in class, make sure that you are able to load it into R as this can be tricky depending on the source. If you are having trouble ask for help before it is too late. Note on reusing datasets from class: Do not reuse datasets used in examples, homework assignments, or labs in the class. Below are a list of data repositories that might be of interest to browse. You’re not limited to these resources, and in fact you’re encouraged to venture beyond them. But you might find something interesting there: TidyTuesday NHS Scotland Open Data Edinburgh Open Data Open access to Scotland’s official statistics Bikeshare data portal UK Gov Data Kaggle datasets OpenIntro datasets Awesome public datasets Youth Risk Behavior Surveillance System (YRBSS) PRISM Data Archive Project Harvard Dataverse If you know of others, let me know, and we’ll add here… 12.3.1 Deliverables Proposal - due [ENTER DUE DATE] Presentation - due [ENTER DUE DATE] Executive summary - due [ENTER DUE DATE] 12.3.1.1 Proposal This is a draft of the introduction section of your project as well as a data analysis plan and your dataset. Section 1 - Introduction: The introduction should introduce your general research question and your data (where it came from, how it was collected, what are the cases, what are the variables, etc.). Section 2 - Data: Place your data in the `/data` folder, and add dimensions and codebook to the README in that folder. Then print out the output of and codebook to the README in that folder. Then print out the output of glimpse() or skim() of your data frame. Section 3 - Data analysis plan: The outcome (response, Y) and predictor (explanatory, X) variables you will use to answer your question. The comparison groups you will use, if applicable. Very preliminary exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data. (You can add to these later as you work on your project.) The method(s) that you believe will be useful in answering your question(s). (You can update these later as you work on your project.) What results from these specific statistical methods are needed to support your hypothesized answer? Each section should be no more than 1 page (excluding figures). You can check a print preview to confirm length. The grading scheme for the project proposal is as follows. Note that after you receive feedback for your proposal you can improve it based on the feedback and re-submit it. If you re-submit, your final score for the proposal will be the average of two scores you receive (first and second submission). Total 10 pts Data 3 pts Proposal 5 pts Workflow, organization, code quality 1 pt Teamwork 1 pt 12.3.1.2 Presentation 5 minutes maximum, and each team member should say something substantial. You can either present live during your workshop or pre-record and submit your video to be played during the workshop. Prepare a slide deck using the template in your repo. This template uses a package called xaringan, and allows you to make presentation slides using R Markdown syntax. There isn’t a limit to how many slides you can use, just a time limit (5 minutes total). Each team member should get a chance to speak during the presentation. Your presentation should not just be an account of everything you tried (“then we did this, then we did this, etc.”), instead it should convey what choices you made, and why, and what you found. Before you finalize your presentation, make sure your chunks are turned off with echo = FALSE. Presentations will take place during the last workshop of the semester. You can choose to do your presentation live or pre-record it. During your workshop you will watch presentations from other teams in your workshop and provide feedback in the form of peer evaluations. The presentation line-up will be generated randomly. The grading scheme for the presentation is as follows: Total 50 pts Time management: Did the team divide the time well amongst themselves or got cut off going over time? 4 pts Content: Is the research question well designed and is the data being used relevant to the research question? 5 pts Professionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project? 5 pts Teamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together? 6 pts Content: Did the team use appropriate statistical procedures and interpretations of results accurately? 10 pts Creativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project? 10 pts Slides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.? 10 pts 12.3.1.3 Executive summary Along with your presentation slides, we want you to provide a brief summary of your project in the README of your repository. This executive summary should provide information on the dataset you’re using, your research question(s), your methodology, and your findings. The executive summary is worth 15 points and will be evaluated based on whether it follows guidance and whether it’s concise but detailed enough. 12.3.1.4 Repo organization The following folders and files in your project repository: presentation.Rmd + presentation.html: Your presentation slides README.Rmd + README.md: Your write-up /data: Your dataset in CSV or RDS format and your data dictionary /proposal: Your project proposal Style and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formatted. 12.3.2 Tips You’re working in the same repo as your teammates now, so merge conflicts will happen, issues will arise, and that’s fine Commit and push often, and ask questions when stuck. Review the marking guidelines below and ask questions if any of the expectations are unclear. Make sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members). Set aside time to work together and apart (physically). When you’re done, review the documents on GitHub to make sure you’re happy with the final state of your work. Then go get some rest! Code: In your presentation your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your R Markdown file I should be able to obtain the results you presented. Exception: If you want to highlight something specific about a piece of code, you’re welcomed to show that portion. Teamwork: You are to complete the assignment as a team. All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works. 12.3.3 Marking Total 100 pts Proposal 10 pts Presentation 50 pts Executive summary 15 pts Reproducibility and organization 10 pts Team peer evaluation 10 pts Classmates’ evaluation 5 pts 12.3.3.1 Criteria Your project will be assessed on the following criteria: Content - What is the quality of research and/or policy question and relevancy of data to those questions? Correctness - Are statistical procedures carried out and explained correctly? Writing and Presentation - What is the quality of the statistical presentation, writing, and explanations? Creativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project? A general breakdown of scoring is as follows: 90%-100% - Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others. 80%-89% - Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others. 70%-79% - Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear. 60%-69% - Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear. Below 60% - Student is not making a sufficient effort. 12.3.3.2 Team peer evaluation You will be asked to fill out a survey where you rate the contribution and teamwork of each team member out of 10 points. You will additionally report a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation.If you are suggesting that an individual did less than 20% of the work, please provide some explanation. If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group. "],["exams.html", "Chapter 13 Exams", " Chapter 13 Exams I don’t think the best assessment method for this curriculum is an exam, but sometimes a take home exam can be an incredible motivator for students without stifling their creativity. I’ve provided two sample take home exams. You probably wouldn’t want to use them verbatim as exams, since they’re now publicly available. But they might give you some idea about how to structure take home exams, how to write directions to reduce issues around plagiarism while still encouraging students to search for resources, etc. Exam 1 [Instructions] [Source] Exam 2 [Instructions] [Source] "],["access-r.html", "Chapter 14 Accessing R 14.1 Setting up your course in RStudio Cloud 14.2 Projects 14.3 Base project template 14.4 Git integration 14.5 Troubleshooting 14.6 Limits 14.7 Learn more", " Chapter 14 Accessing R One of the design principles of this course is “cherish day one” – get students from nothing to their first meaningful data visualization within the first 10 minutes of the course. Achieving this is possible, but requires careful consideration of the computing infrastructure. This section outlines how one can set up their course to run on RStudio Cloud, use GitHub for not only version control and collaboration but also as the learning management system for the course, and build their course materials with packages from the *down universe (rmarkdown, blogdown, xaringan, etc.). Lastly, the alternative setups section describes other approaches to setting up the computing infrastructure that can be just as efficient and effective as the ones described in the main choices for the course, and discusses pros and cons. The RStudio IDE includes a viewable environment, a file browser, data viewer, and a plotting pane, which makes it less intimidating than the bare R shell. Additionally, since it is a full fledged IDE, it also features integrated help, syntax highlighting, and context-aware tab completion, which are all powerful tools that help flatten the learning curve. RStudio Cloud is a managed cloud instance of the RStudio IDE. We recommend having students access RStudio via RStudio Cloud as opposed to using a local installation. The main reason for this choice is reducing friction at first exposure to R. Local installation can be difficult to manage, both for the student and the instructor, and can shift the focus away from data science learning at the beginning of the course. We discuss in further detail the reasons for avoiding local installation at the beginning of the course in Section 2.3 When you create an account on RStudio Cloud, you get a workspace of your own, and the projects you create here can be public or private. You can also add a new workspace and control its permissions, and the projects you create here can also be public or private. The RStudio Cloud workspace for Data Science Course in a Box project is here. You can join the workspace and play around with the application exercises. A natural way to set up a course in RStudio Cloud is using a private workspace. In this structure a classroom (a cohort of students in one semester of the course) maps to a workspace. Once a workspace is set up, instructors can invite students to the workspace via an invite link. Workspaces allow for various permission levels which can be assigned to students, teaching assistants, and instructors. Then, each assignment/project in the course maps to an RStudio Cloud project. Figure 14.1: RStudio Cloud classroom structure 14.1 Setting up your course in RStudio Cloud First, create a new workspace on RStudio Cloud. By default, this new workspace will be a private workspace. All it takes to create a new workspace is a name and brief information for the space. You can update the information once the space is created, however you can’t change the name of the space. For the name, I recommend using something along the lines of Course number - Semester. Figure 14.2: Creating a new workspace on RStudio Cloud Next step is to invite members to the workspace. You can do this by sending invitations or using a sharing link. I recommend using the latter approach for efficiency. Once all of your students are in the course (or once drop/add period ends) you can change the settings so that additional members cannot join throughout the semester using the sharing link, and can only be added via an invitation from the instructor. Figure 14.3: Setting workspace permissions As highlighted in the figure above, when a workspace is set to accept members via a shared link, the owner can also set a default permission level for those entering the workspace via the sharing link. Suggested permission levels and suggestions for mapping to course roles are as follows. RStudio Cloud role Permissions Course role Admin Manage users, view, edit and manage all projects Instructor Moderator View, edit and manage all projects Teaching Assistant Contributor Create, edit and manage their own projects Student Viewer View projects shared with everyone Auditor, Visitor This set of permissions will allow instructors full access including management of users. Teaching assistants will be able to peek into student projects, which can be very useful when helping troubleshoot. Students won’t be able to see each others’ projects. Students auditing your course or visitors, such as colleagues wanting to view/experience your course setup will have limited access. RStudio Cloud also allows you to specify who can see the list of members. Admins and moderators can, by default, see all members of the workspace. I prefer to allow contributors (students) to see the list of members and viewers (auditors and visitors) to not since course enrollment information should not be available to non-official members of the course. 14.2 Projects A project in RStudio Cloud is equivalent to an RStudio project. If you are an RStudio user, but you don’t use projects, I highly recommend considering switching your workflow to include projects. You can learn more about them here. Figure 14.4: A new project in RStudio Cloud is a new project in the RStudio IDE 14.2.1 Access When you create a new project in your workspace, it is by default visible only to you plus the admins and moderators of the space. This default has two advantages: It allows you to develop a project semi-privately and actively decide when the project is ready to be shared with students. This can be especially beneficial when developing an assessment like an exam. It means when a student creates a project in the workspace it’s not, by default, visible to other students. When your project is ready to be shared with the students in your course, you can adjust the access level by clicking on the gear icon to reveal the settings menu. You should also check the “Make this project an assignment” box so that when a student starts their assignment RStudio Cloud automatically makes a copy of the project for them. Figure 14.5: Setting project permissions within a workspace 14.3 Base project template If you consistently use a particular set of packages and/or need a particular set of documents to be included in each project, the base project template functionality will come in very handy. You can use this by defining a base project template for the space. Simply create a new project and add any packages or files you want projects created in the space to start with. After creating your project, select it on the Settings page as the base project template. Figure 14.6: Selecting a base project template Note that a project must be shared with everyone in the space in order to be used as a template; only projects which are viewable by everyone in the space will appear in the templates list. You can update your base project as many times as you want throughout the semester. The base template is applied prospectively – it only effects projects created after the template has been set. Therefore updating the base project will not break projects already created with the previous version of a base project. 14.4 Git integration It is possible to create (clone) a new project in RStudio Cloud from a GitHub repository, just like in the RStudio IDE. Figure 14.7: Creating a new project from GitHub repository If you have a base project template set up for your workspace, this new project created from GitHub will also have the packages installed in the base project template. For more on using Git and GitHub in the classroom, see Section 15. 14.5 Troubleshooting I strongly recommend that you make a second account for themselves on RStudio Cloud and add that user as a contributor to the workspace to be able to see what your students see when they log in. It’s a great way to test out functionality and resolve unexpected issues your students might encounter, before they encounter them. I recommend using an incognito browser window for the student account so that you can stay logged in both as a student and as the instructor at the same time and test the student view as you develop content as an instructor. One huge advantage of your students working in RStudio Cloud is that you as the instructor, and anyone with an admin and moderator role, can peek into student projects. While it is important for your students to learn to ask questions in a way that does not depend on someone else being able to see their work directly (and for this I strongly recommend teaching students to make reprexes), it is sometimes, especially early on, nice to be able to peek into a student’s project. 14.6 Limits 14.6.1 Memory &amp; CPU Each project on RStudio Cloud is allocated 1 GB of RAM and 1 CPU by default. While this is a pretty generous limit, actions like joining very large tables or fitting complicated models could exceed the limit. I recommend testing out the any work you assign, especially those using large datasets, in order to avoid unexpected hiccups due to out of memory issues. One challenge is that you might have no control over what issues students might run into if they are working on an open ended project using a dataset of their own choice. In these circumstances it’s helpful to keep in the back of your mind that one way an out of memory issue can present itself is with the RStudio Cloud project crashing. 14.6.2 Other limits For most up to date information on limits on free RStudio Cloud accounts, as well as any other technical details, see the RStudio Cloud Guide. This document gets updated as changes are made to the user interface and/or the backend of RStudio Cloud and should be assumed to be more current than the information outlined here. 14.7 Learn more To see this all in action and learn more, watch the following RStudio Cloud webinars: Teaching R online with RStudio Cloud (July 2020) Teaching R online with RStudio Cloud (March 2020) RStudio Cloud in the Classroom Note that as of August 2020 RStudio Cloud offers paid tiers as well, and you will likely need a paid subscription to teach with RStudio Cloud (unless you’re teaching a short, small course). Depending on your institution’s IT infrastructure and your class size, RStudio Cloud may or may not be the most economically feasible solution for your teaching needs. See Section 18 for suggestions for other setups for providing server access to RStudio for your students. Note that these alternatives generally require system infrastructure expertiose or IT professional time.↩︎ "],["version-control.html", "Chapter 15 Version control 15.1 Git 15.2 GitHub 15.3 ghclass 15.4 Learn more", " Chapter 15 Version control One of the defining principles behind how this course teaches computing is that everything the instructor and the students produce should be reproducible – how you get a result is just as important as the result itself. Implicit in the idea of reproducibility is collaboration, the code you produce is documentation of the process and it is critical to share it (even if only with yourself in the future). One of the goals of this course is to teach students tools that make this documentation and collaboration as robust and painless as possible. This is best accomplished with a distributed version control system like Git This course adopts a top down approach to teaching Git – students are required to use it for all assignments. These type of tools tend to suffer from delayed gratification as when they are first introduced students view them as a clunky addition to their workflow and it is not until weeks or even months later that they experience the value first hand. If this section doesn’t convince you that you should be using Git and GitHub in your data science course, the section on [alternative setups][alternative_setups] describes how to leverage RStudio Cloud features for assignment dissemination, collection, and providing feedback. You can also use your own institution’s learning management system for this purpose as well. 15.1 Git Learning Git is a steep hill to climb, but with appropriate and user friendly tooling and careful pedagogy, being able to use core functionality of git for the purposes of version control in a data analysis context doesn’t have to be. The learning curve for Git is unavoidable but I have found it best to focus on core functionality. Specifically, I teach a simple centralized git workflow which uses RStudio’s project based git GUI. Each new assignment starts with creating a new project from git (i.e. clone), the RStudio git GUI continuously displays git status and allows users to add, rm, commit, push, and pull. These happen to be the most commonly used git commands, and using only these students will be able to do most of what they need to do to work and collaborate on assignments and submit them. However it is not unusual for students to mangle their repositories such that the command line tools become necessary, and when this happens, the instruction team can help students get out of the rut. The most complicated task students regularly encounter are merge conflicts, most of which are straight forward to resolve. Students often develop elaborate workflows to avoid these types of issues but they eventually come to understand the resolution process. It is super important to encourage students to commit early and often to reduce the size of each change. Finally, in the early stages of learning git it is useful to engineer situations in which students encounter problems while they are in the classroom so that the professor and teaching assistants are present to troubleshoot and walk them through the process in person. A sample activity for resolving merge conflicts is provided in the course materials here. 15.2 GitHub The use of GitHub also goes a long way to help students visualize and understand the git process which also aids in student buy-in. The web interface allows students to easily view diffs (file changes over time) in files they are collaborating on, keep track of commit histories, and search both the current state as well as the entire history of the code base. Within the classroom GitHub can be thought of as an advanced and flexible learning management system (compared to traditional tools like Blackboard or Sakai). At its most basic, GitHub can be used as a central repository where students turn in their work and where the professor and teaching assistants then collect it and provide feedback. However using this ecosystem for only assignment submission ignores the most compelling features and advantages. In our classes students are expected to push their work in progress throughout the assignment period. This is not enforced explicitly, but rather through the design of the assignments. Most assignments are large scale and team based, meaning no one student can easily complete all the work on their own. In addition, the various tasks within the assignment are interdependent, meaning students are not able to divide up the work and complete each piece individually. This type of design strongly encourages the students to share their work in progress which they are able to do using GitHub. This is also useful to the instructor as it allows for opportunities for observation and feedback through the course of the assignment without forcing students to turn in “drafts”. Additionally, GitHub’s organization and teams features are a natural fit for managing course related tasks. We have used a model where each class has a separate organization to which the students are invited at the beginning of the semester. Students have individual and team personas on GitHub, and are given write access to repos for assignments accordingly, depending on whether the assignment is to be completed individually or in teams. In general, I have found that using one repository per team per assignment works best. This creates a LOT of repositories by the end of the semester, but that’s okay! In order to comply with Family Educational Rights and Privacy Act (FERPA) requirements all student repositories are kept private by default, which is possible at no cost thanks to GitHub’s generous academic discount policy. Setup and management for larger classes can be challenging due to the sheer number of components, however most actions can be scripted via the GitHub API which can dramatically reduce the course administrative workload. Two solutions to this problem are (1) GitHub Classroom and (2) ghclass. Use of ghclass, an R package for GitHub classroom tools is detailed below, and use of GitHub classroom is described in the [alternative setups][alternative_setups] section. 15.3 ghclass The ghclass package is designed to enable instructors to efficiently manage their courses on GitHub. It has a wide range of functionality for managing organizations, teams, repositories, and users on GitHub and helps automate most of the tedious and repetitive tasks around creating and distributing assignments. If you would like to learn more about using ghclass to set up your course on GitHub, I strongly recommend reviewing the video and materials from the following 1.5 hr workshop: Teaching computing with Git and GitHub. 15.4 Learn more If you would like to learn more about teaching with version control, I recommend the following paper. Beckman, M. D., Çetinkaya-Rundel, M., Horton, N. J., Rundel, C. W., Sullivan, A. J., &amp; Tackett, M. (2020). Implementing version control with Git and GitHub as a learning objective in statistics and data science courses. doi.org/10.1080/10691898.2020.1848485 If you would like to learn more about using version control with R, I strongly recommend Happy Git with R. "],["discussion.html", "Chapter 16 Discussion", " Chapter 16 Discussion My recommended tool for course discussion is Piazza. I have, in the past, used Slack for course communication as well. Slack has the advantage of being real-life feeling as well as being the communication tool of choice for many data science teams. However it doesn’t work well for lasting class discussions as threading and searchability are poor. Additionally, the instructor does not have the option to edit student questions, which can be frustrating if they have not formatted their code appropriately. Similar tools like Discord and MS Teams have similar advantages when it comes to real-life discussions and similar disadvantages when it comes to threading and searchability. Other options are GitHub issues and GitHub Discussions, especially for courses using version control. "],["sharing.html", "Chapter 17 Sharing", " Chapter 17 Sharing A nifty tool for building your course website is blogdown. Perhaps the most useful aspect of blogdown in this setting is that your slides, assignments, etc. written in R Markdown can be automatically rendered, so you don’t need to separately knit those documents. If you would like to build your course website with blogdown, you can use this course website as an example, source code here. This webinar by Alison Hill and Desirée De Leon is also very useful for options for sharing your course materials with students. "],["alternative-setups.html", "Chapter 18 Alternative setups 18.1 Centralized RStudio server 18.2 Dockerized RStudio server 18.3 Learn more", " Chapter 18 Alternative setups In this section we describe alternative setups for your course. In a course at this level students should access the RStudio IDE through a centralized RStudio server instance, which allows us to provide students with uniform computing environments. It should be noted that the goal isn’t to completely dissuade students from downloading and installing R and RStudio locally, we just don’t want it to be a prerequisite for getting started. Teaching personal setup is best done progressively throughout a semester, usually via one-on-one interactions during office hours or after class. The goal is that all students will be able to continue using R even if they no longer have access to departmental resources. If you prefer to not use RStudio Cloud, you might consider one of the following approaches. 18.1 Centralized RStudio server One approach that might work particularly well for higher level courses that require a shared infrastructure and higher end computational resources is running academically licensed RStudio Server Pro on a powerful server (e.g. 32 cores, 512 GB RAM). If this server is in the department, instructors can be given direct control over all aspects of the computing environment. The figure below is a sketch of the architecture of the centralized RStudio server approach, which shows that students connect to a single RStudio server instance via a departmental login. This works well for upper division and graduate level courses as most students are directly affiliated with the department. Students taking courses who are not affiliated with the department are issued temporary visitor accounts which expire at the end of the semester. Figure 18.1: Centralized RStudio server More modest configurations can be more than adequate (e.g., a mid-to-high end desktop) for the vast majority of use cases, however care should be given when working with larger datasets in a shared environment. An alternative approach is to use a virtualized hardware in the cloud (e.g. EC2, Azure, etc.). The primary benefit of running and managing the server in-house comes down to control - as needed the instructor(s) are able to install and update software, change configurations, restart or kill sessions, and monitor all aspects of the system. This does increase the demands on the instructor and any involved IT staff, but we have found the benefits to far outweigh the costs. One other unforeseen benefit to a centralized approach is that it makes it possible to present large scale analytic tasks that would not be possible on a traditional desktop or laptop. For example, advanced courses can include homework assignments where students need to process a dataset that is on the order of several hundred gigabytes in size, which would not be possible if they were required to use their own system. 18.2 Dockerized RStudio server A second approach to running RStudio server involves the construction and hosting of a farm of individualized Docker container instances. A sketch of the architecture of the Docker containers is in the figure below, which shows that students authenticate via university login which redirects them to a personal RStudio instance running in a Docker container on either a local or cloud based server. Figure 18.2: Dockerized RStudio server Docker is a popular and rapidly evolving containerization tool suite that allows users to automate the deployment of software in a repeatable and self-contained way. Each container wraps a portion of the file system in such a way that all of the code, runtimes, tools, and libraries needed for a piece of software are available, meaning that software will always run in exactly the same way regardless of the environment in which it is being run. As such, Docker is a powerful tool for reproducible computational research, since every Dockerfile transparently and clearly defines exactly what software and which version is being used for any particular computation task. An additional advantage of Docker containers is that they are similar to virtual machines in that they are sandboxed from one another. By mapping each student to a single container we are able to keep all student processes segregated and enforce strict CPU, memory, and disk usage quotas to avoid accidental disruption of the work of one another. However Docker containers are generally lighter weight than virtual machines, in terms of system resources used. This makes it feasible to run a large number of containers on a single system at the same time. Since most RStudio usage (particularly by our introductory students) is intermittent, we have found that it is possible to run more than 100 RStudio containers concurrently on a single server. Servers can be run locally or on a cloud-based service. The cost for the latter can be defrayed by the credits many services offer for academic use. Further details of a containerized RStudio server approach implemented at Duke can be found at here. This repository contains a README which explains how the large-scale container farm is set up and also contains the Dockerfiles that are used to create the individual containers. Implementing the infrastructure solutions discussed above can be overwhelming and time consuming. We encourage faculty interested in adopting these tools to partner with their departmental and/or university IT professionals. Additionally, building these partnerships can lead to collaborations that benefit the entire university. 18.3 Learn more If you would like to learn more about computing infrastructure for statistics and data science courses, we recommend the following paper. Çetinkaya-Rundel, M., &amp; Rundel, C. (2018). Infrastructure and tools for teaching computing throughout the statistical curriculum. The American Statistician, 72(1), 58-65. doi.org/10.1080/00031305.2017.1397549 A freely available version of the paper can be found here. "],["pedagogy.html", "Chapter 19 Pedagogy 19.1 Course design 19.2 Teaching the tidyverse", " Chapter 19 Pedagogy 19.1 Course design The following resources describe the pedagogy used in designing and teaching a course with the materials provided in this resources. Mine Çetinkaya-Rundel &amp; Victoria Ellison. A fresh look at introductory data science, Journal of Statistics Education. doi.org/10.1080/10691898.2020.1804497. Talk: The art and science of teaching data science [Slides] Talk: Data Science in a Box [Slides] [Video] Talk: Let them eat cake (first)! [Slides] [Video] 19.2 Teaching the tidyverse The following four part blog post series offers recommendations and tips for teaching the tidyverse in 2020. Part 1: Getting started Part 2: Data visualisation Part 3: Data wrangling and tidying Part 4: When to purrr? "],["schedule.html", "Chapter 20 Schedule 20.1 11-week schedule 20.2 15-week schedule", " Chapter 20 Schedule There are a lot of materials in Data Science Course in a Box, which allows instructors to pick and choose what they want depending on the length of the course they’re teaching, their audience, and the curriculum within which the course is placed. The following are two options for course schedules, one for a 11-week course and the other for a 15-week course. 20.1 11-week schedule Unit Week Title Type 1 1 Welcome to data science! Lecture 1 1 Meet the toolkit: Programming Lecture 1 1 Meet the toolkit: Version control &amp; collaboration Lecture 1 1 Hello R Lab 1 1 Pet names Homework 2 2 Data and visualisation Lecture 2 2 Visualising data with ggplot2 Lecture 2 2 Visualising numerical data Lecture 2 2 Visualising categorical data Lecture 2 2 StarWars + Dataviz Application exercise 2 2 Plastic waste Lab 2 2 Airbnb listings in Edinburgh Homework 2 3 Tidy data Lecture 2 3 Grammar of data wrangling Lecture 2 3 Working with a single data frame Lecture 2 3 Working with multiple data frames Lecture 2 3 Tidying data Lecture 2 3 Hotels + Data wrangling Application exercise 2 3 Nobel laureates Lab 2 3 Road traffic accidents Homework 2 4 Data types Lecture 2 4 Data classes Lecture 2 4 Importing data Lecture 2 4 Recoding data Lecture 2 4 Hotels + Data types Application exercise 2 4 Nobels + Sales + Data import Application exercise 2 4 Option 1: La Quinta is Spanish for next to Denny’s, Pt. 1 Option 2: La Quinta is Spanish for next to Denny’s, Pt. 2 Lab 2 4 College majors Homework 2 5 Tips for effective data visualization Lecture 2 5 Brexit + Telling stories with dataviz Application exercise 2 5 Scientific studies and confounding Lecture 2 5 Simpson’s paradox Lecture 2 5 Doing data science Lecture 2 5 Option 1: Take a sad plot and make it better Option 2: Simpson’s paradox Lab 2 5 Legos Homework 2 6 Web scraping Lecture 2 6 Scraping top 250 movies on IMDB Lecture 2 6 Web scraping considerations Lecture 2 6 IMDB + Web scraping Application exercise 2 6 Functions Lecture 2 6 Iteration Lecture 2 6 University of Edinburgh Art Collection Lab 2 6 Money in politics Homework 3 7 Misrepresentation Lecture 3 7 Data privacy Lecture 3 7 Algorithmic bias Lecture 3 7 Conveying the right message through visualisation Lab 3 7 Project proposals Project 4 8 Fitting and interpreting models Lecture 4 8 Modelling nonlinear relationships Lecture 4 8 Models with multiple predictors Lecture 4 8 More models with multiple predictors Lecture 4 8 Grading the professor, Pt 1 Lab 4 8 Option 1: Bike rentals in DC Option 2: Peer review of project proposals Homework 4 9 Logistic regression Lecture 4 9 Prediction and overfitting Lecture 4 9 Feature engineering Lecture 4 9 Grading the professor, Pt 1 Lab 4 9 Exploring the GSS Homework 4 10 Cross validation Lecture 4 10 The Office, Part 1 Application exercise 4 10 The Office, Part 2 Application exercise 4 10 Quantifying uncertainty Lecture 4 10 Bootstrapping Lecture 4 10 Option 1: Smoking during pregnancy Option 2: Work on projects Option 3: Collaboration on GitHub Lab 4 10 Modelling the GSS Homework 5 11 Text analysis Lecture 5 11 Comparing texts Lecture 5 11 Interactive web apps Lecture 5 11 Machine learning Lecture 5 11 Project presentations Lab 5 11 Wrap up Homework 20.2 15-week schedule Unit Week Title Type 1 1 Welcome to data science! Lecture 1 1 Meet the toolkit: Programming Lecture 1 1 Meet the toolkit: Version control &amp; collaboration Lecture 1 1 Hello R Lab 1 1 Pet names Homework 2 2 Data and visualisation Lecture 2 2 Visualising data with ggplot2 Lecture 2 2 Visualising numerical data Lecture 2 2 Visualising categorical data Lecture 2 2 StarWars + Dataviz Application exercise 2 2 Plastic waste Lab 2 2 Airbnb listings in Edinburgh Homework 2 3 Tidy data Lecture 2 3 Grammar of data wrangling Lecture 2 3 Working with a single data frame Lecture 2 3 Working with multiple data frames Lecture 2 3 Tidying data Lecture 2 3 Hotels + Data wrangling Application exercise 2 3 Nobel laureates Lab 2 3 Road traffic accidents Homework 2 4 Data types Lecture 2 4 Data classes Lecture 2 4 Recoding data Lecture 2 4 Hotels + Data types Application exercise 2 4 La Quinta is Spanish for next to Denny’s, Pt. 1 Lab 2 4 College majors Homework 2 5 Importing data Lecture 2 5 Nobels + Sales + Data import Application exercise 2 5 Tips for effective data visualization Lecture 2 5 Brexit + Telling stories with dataviz Application exercise 2 5 Take a sad plot and make it better Lab 2 5 La Quinta is Spanish for next to Denny’s, Pt. 2 Homework 2 6 Scientific studies and confounding Lecture 2 6 Simpson’s paradox Lecture 2 6 Doing data science Lecture 2 6 Simpson’s paradox Lab 2 6 Legos Homework 2 7 Web scraping Lecture 2 7 Scraping top 250 movies on IMDB Lecture 2 7 Web scraping considerations Lecture 2 7 IMDB + Web scraping Application exercise 2 7 Work on projects Lab 2 7 Work on projects Homework 2 8 Functions Lecture 2 8 Iteration Lecture 2 8 University of Edinburgh Art Collection Lab 2 8 Money in politics Homework 3 9 Misrepresentation Lecture 3 9 Data privacy Lecture 3 9 Algorithmic bias Lecture 3 9 Conveying the right message through visualisation Lab 3 9 Project proposals Project 3 9 Peer review of project proposals Homework 4 10 Fitting and interpreting models Lecture 4 10 Modelling nonlinear relationships Lecture 4 10 Models with multiple predictors Lecture 4 10 More models with multiple predictors Lecture 4 10 Grading the professor, Pt 1 Lab 4 10 Bike rentals in DC Homework 4 11 Logistic regression Lecture 4 11 Prediction and overfitting Lecture 4 11 Feature engineering Lecture 4 11 Grading the professor, Pt. 1 Lab 4 11 Exploring the GSS Homework 4 12 Cross validation Lecture 4 12 The Office, Part 1 Application exercise 4 12 The Office, Part 2 Application exercise 4 12 Bootstrapping Lecture 4 12 Work on projects Lab 4 12 Grading the professor, Pt. 2 Homework 4 13 Quantifying uncertainty Lecture 4 13 Bootstrapping Lecture 4 13 Hypothesis testing Lecture 4 13 Inference overview Lecture 4 13 Smoking during pregnancy Lab 4 13 Modelling the GSS Homework 5 14 Text analysis Lecture 5 14 Comparing texts Lecture 5 14 Interactive web apps Lecture 5 14 Machine learning Lecture 5 14 Collaborating on GitHub Lab 5 14 Wrap up Homework 5 15 Bayesian inference Lecture 5 15 Building interactive web apps, Pt. 1 Lecture 5 15 Building interactive web apps, Pt. 1 Lecture 5 15 Project presentations Lab 5 15 N/A Homework "]]
